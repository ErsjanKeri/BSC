{"model_name": "temp_model", "total_size_bytes": 2200281088, "metadata": {"n_layers": 22, "n_vocab": 32000, "n_embd": 2048, "n_tensors": 201}, "tensors": [{"name": "output.weight", "offset_start": 736160, "offset_end": 131808160, "size_bytes": 131072000, "shape": [2048, 32000], "category": "output", "layer_id": null, "component": "output", "component_type": "Output Projection"}, {"name": "token_embd.weight", "offset_start": 131808160, "offset_end": 262880160, "size_bytes": 131072000, "shape": [2048, 32000], "category": "embedding", "layer_id": null, "component": "other", "component_type": "Token Embeddings"}, {"name": "blk.0.attn_norm.weight", "offset_start": 262880160, "offset_end": 262888352, "size_bytes": 8192, "shape": [2048], "category": "attention", "layer_id": 0, "component": "norm", "component_type": "Attention Norm"}, {"name": "blk.0.ffn_down.weight", "offset_start": 262888352, "offset_end": 285957024, "size_bytes": 23068672, "shape": [5632, 2048], "category": "ffn", "layer_id": 0, "component": "down", "component_type": "FFN Down"}, {"name": "blk.0.ffn_gate.weight", "offset_start": 285957024, "offset_end": 309025696, "size_bytes": 23068672, "shape": [2048, 5632], "category": "ffn", "layer_id": 0, "component": "gate", "component_type": "FFN Gate"}, {"name": "blk.0.ffn_up.weight", "offset_start": 309025696, "offset_end": 332094368, "size_bytes": 23068672, "shape": [2048, 5632], "category": "ffn", "layer_id": 0, "component": "up", "component_type": "FFN Up"}, {"name": "blk.0.ffn_norm.weight", "offset_start": 332094368, "offset_end": 332102560, "size_bytes": 8192, "shape": [2048], "category": "ffn", "layer_id": 0, "component": "norm", "component_type": "FFN Norm"}, {"name": "blk.0.attn_k.weight", "offset_start": 332102560, "offset_end": 333151136, "size_bytes": 1048576, "shape": [2048, 256], "category": "attention", "layer_id": 0, "component": "key", "component_type": "Attention K"}, {"name": "blk.0.attn_output.weight", "offset_start": 333151136, "offset_end": 341539744, "size_bytes": 8388608, "shape": [2048, 2048], "category": "attention", "layer_id": 0, "component": "output", "component_type": "Output Projection"}, {"name": "blk.0.attn_q.weight", "offset_start": 341539744, "offset_end": 349928352, "size_bytes": 8388608, "shape": [2048, 2048], "category": "attention", "layer_id": 0, "component": "query", "component_type": "Attention Q"}, {"name": "blk.0.attn_v.weight", "offset_start": 349928352, "offset_end": 350976928, "size_bytes": 1048576, "shape": [2048, 256], "category": "attention", "layer_id": 0, "component": "value", "component_type": "Attention V"}, {"name": "blk.1.attn_norm.weight", "offset_start": 350976928, "offset_end": 350985120, "size_bytes": 8192, "shape": [2048], "category": "attention", "layer_id": 1, "component": "norm", "component_type": "Attention Norm"}, {"name": "blk.1.ffn_down.weight", "offset_start": 350985120, "offset_end": 374053792, "size_bytes": 23068672, "shape": [5632, 2048], "category": "ffn", "layer_id": 1, "component": "down", "component_type": "FFN Down"}, {"name": "blk.1.ffn_gate.weight", "offset_start": 374053792, "offset_end": 397122464, "size_bytes": 23068672, "shape": [2048, 5632], "category": "ffn", "layer_id": 1, "component": "gate", "component_type": "FFN Gate"}, {"name": "blk.1.ffn_up.weight", "offset_start": 397122464, "offset_end": 420191136, "size_bytes": 23068672, "shape": [2048, 5632], "category": "ffn", "layer_id": 1, "component": "up", "component_type": "FFN Up"}, {"name": "blk.1.ffn_norm.weight", "offset_start": 420191136, "offset_end": 420199328, "size_bytes": 8192, "shape": [2048], "category": "ffn", "layer_id": 1, "component": "norm", "component_type": "FFN Norm"}, {"name": "blk.1.attn_k.weight", "offset_start": 420199328, "offset_end": 421247904, "size_bytes": 1048576, "shape": [2048, 256], "category": "attention", "layer_id": 1, "component": "key", "component_type": "Attention K"}, {"name": "blk.1.attn_output.weight", "offset_start": 421247904, "offset_end": 429636512, "size_bytes": 8388608, "shape": [2048, 2048], "category": "attention", "layer_id": 1, "component": "output", "component_type": "Output Projection"}, {"name": "blk.1.attn_q.weight", "offset_start": 429636512, "offset_end": 438025120, "size_bytes": 8388608, "shape": [2048, 2048], "category": "attention", "layer_id": 1, "component": "query", "component_type": "Attention Q"}, {"name": "blk.1.attn_v.weight", "offset_start": 438025120, "offset_end": 439073696, "size_bytes": 1048576, "shape": [2048, 256], "category": "attention", "layer_id": 1, "component": "value", "component_type": "Attention V"}, {"name": "blk.10.attn_norm.weight", "offset_start": 439073696, "offset_end": 439081888, "size_bytes": 8192, "shape": [2048], "category": "attention", "layer_id": 10, "component": "norm", "component_type": "Attention Norm"}, {"name": "blk.10.ffn_down.weight", "offset_start": 439081888, "offset_end": 462150560, "size_bytes": 23068672, "shape": [5632, 2048], "category": "ffn", "layer_id": 10, "component": "down", "component_type": "FFN Down"}, {"name": "blk.10.ffn_gate.weight", "offset_start": 462150560, "offset_end": 485219232, "size_bytes": 23068672, "shape": [2048, 5632], "category": "ffn", "layer_id": 10, "component": "gate", "component_type": "FFN Gate"}, {"name": "blk.10.ffn_up.weight", "offset_start": 485219232, "offset_end": 508287904, "size_bytes": 23068672, "shape": [2048, 5632], "category": "ffn", "layer_id": 10, "component": "up", "component_type": "FFN Up"}, {"name": "blk.10.ffn_norm.weight", "offset_start": 508287904, "offset_end": 508296096, "size_bytes": 8192, "shape": [2048], "category": "ffn", "layer_id": 10, "component": "norm", "component_type": "FFN Norm"}, {"name": "blk.10.attn_k.weight", "offset_start": 508296096, "offset_end": 509344672, "size_bytes": 1048576, "shape": [2048, 256], "category": "attention", "layer_id": 10, "component": "key", "component_type": "Attention K"}, {"name": "blk.10.attn_output.weight", "offset_start": 509344672, "offset_end": 517733280, "size_bytes": 8388608, "shape": [2048, 2048], "category": "attention", "layer_id": 10, "component": "output", "component_type": "Output Projection"}, {"name": "blk.10.attn_q.weight", "offset_start": 517733280, "offset_end": 526121888, "size_bytes": 8388608, "shape": [2048, 2048], "category": "attention", "layer_id": 10, "component": "query", "component_type": "Attention Q"}, {"name": "blk.10.attn_v.weight", "offset_start": 526121888, "offset_end": 527170464, "size_bytes": 1048576, "shape": [2048, 256], "category": "attention", "layer_id": 10, "component": "value", "component_type": "Attention V"}, {"name": "blk.11.attn_norm.weight", "offset_start": 527170464, "offset_end": 527178656, "size_bytes": 8192, "shape": [2048], "category": "attention", "layer_id": 11, "component": "norm", "component_type": "Attention Norm"}, {"name": "blk.11.ffn_down.weight", "offset_start": 527178656, "offset_end": 550247328, "size_bytes": 23068672, "shape": [5632, 2048], "category": "ffn", "layer_id": 11, "component": "down", "component_type": "FFN Down"}, {"name": "blk.11.ffn_gate.weight", "offset_start": 550247328, "offset_end": 573316000, "size_bytes": 23068672, "shape": [2048, 5632], "category": "ffn", "layer_id": 11, "component": "gate", "component_type": "FFN Gate"}, {"name": "blk.11.ffn_up.weight", "offset_start": 573316000, "offset_end": 596384672, "size_bytes": 23068672, "shape": [2048, 5632], "category": "ffn", "layer_id": 11, "component": "up", "component_type": "FFN Up"}, {"name": "blk.11.ffn_norm.weight", "offset_start": 596384672, "offset_end": 596392864, "size_bytes": 8192, "shape": [2048], "category": "ffn", "layer_id": 11, "component": "norm", "component_type": "FFN Norm"}, {"name": "blk.11.attn_k.weight", "offset_start": 596392864, "offset_end": 597441440, "size_bytes": 1048576, "shape": [2048, 256], "category": "attention", "layer_id": 11, "component": "key", "component_type": "Attention K"}, {"name": "blk.11.attn_output.weight", "offset_start": 597441440, "offset_end": 605830048, "size_bytes": 8388608, "shape": [2048, 2048], "category": "attention", "layer_id": 11, "component": "output", "component_type": "Output Projection"}, {"name": "blk.11.attn_q.weight", "offset_start": 605830048, "offset_end": 614218656, "size_bytes": 8388608, "shape": [2048, 2048], "category": "attention", "layer_id": 11, "component": "query", "component_type": "Attention Q"}, {"name": "blk.11.attn_v.weight", "offset_start": 614218656, "offset_end": 615267232, "size_bytes": 1048576, "shape": [2048, 256], "category": "attention", "layer_id": 11, "component": "value", "component_type": "Attention V"}, {"name": "blk.12.attn_norm.weight", "offset_start": 615267232, "offset_end": 615275424, "size_bytes": 8192, "shape": [2048], "category": "attention", "layer_id": 12, "component": "norm", "component_type": "Attention Norm"}, {"name": "blk.12.ffn_down.weight", "offset_start": 615275424, "offset_end": 638344096, "size_bytes": 23068672, "shape": [5632, 2048], "category": "ffn", "layer_id": 12, "component": "down", "component_type": "FFN Down"}, {"name": "blk.12.ffn_gate.weight", "offset_start": 638344096, "offset_end": 661412768, "size_bytes": 23068672, "shape": [2048, 5632], "category": "ffn", "layer_id": 12, "component": "gate", "component_type": "FFN Gate"}, {"name": "blk.12.ffn_up.weight", "offset_start": 661412768, "offset_end": 684481440, "size_bytes": 23068672, "shape": [2048, 5632], "category": "ffn", "layer_id": 12, "component": "up", "component_type": "FFN Up"}, {"name": "blk.12.ffn_norm.weight", "offset_start": 684481440, "offset_end": 684489632, "size_bytes": 8192, "shape": [2048], "category": "ffn", "layer_id": 12, "component": "norm", "component_type": "FFN Norm"}, {"name": "blk.12.attn_k.weight", "offset_start": 684489632, "offset_end": 685538208, "size_bytes": 1048576, "shape": [2048, 256], "category": "attention", "layer_id": 12, "component": "key", "component_type": "Attention K"}, {"name": "blk.12.attn_output.weight", "offset_start": 685538208, "offset_end": 693926816, "size_bytes": 8388608, "shape": [2048, 2048], "category": "attention", "layer_id": 12, "component": "output", "component_type": "Output Projection"}, {"name": "blk.12.attn_q.weight", "offset_start": 693926816, "offset_end": 702315424, "size_bytes": 8388608, "shape": [2048, 2048], "category": "attention", "layer_id": 12, "component": "query", "component_type": "Attention Q"}, {"name": "blk.12.attn_v.weight", "offset_start": 702315424, "offset_end": 703364000, "size_bytes": 1048576, "shape": [2048, 256], "category": "attention", "layer_id": 12, "component": "value", "component_type": "Attention V"}, {"name": "blk.13.attn_norm.weight", "offset_start": 703364000, "offset_end": 703372192, "size_bytes": 8192, "shape": [2048], "category": "attention", "layer_id": 13, "component": "norm", "component_type": "Attention Norm"}, {"name": "blk.13.ffn_down.weight", "offset_start": 703372192, "offset_end": 726440864, "size_bytes": 23068672, "shape": [5632, 2048], "category": "ffn", "layer_id": 13, "component": "down", "component_type": "FFN Down"}, {"name": "blk.13.ffn_gate.weight", "offset_start": 726440864, "offset_end": 749509536, "size_bytes": 23068672, "shape": [2048, 5632], "category": "ffn", "layer_id": 13, "component": "gate", "component_type": "FFN Gate"}, {"name": "blk.13.ffn_up.weight", "offset_start": 749509536, "offset_end": 772578208, "size_bytes": 23068672, "shape": [2048, 5632], "category": "ffn", "layer_id": 13, "component": "up", "component_type": "FFN Up"}, {"name": "blk.13.ffn_norm.weight", "offset_start": 772578208, "offset_end": 772586400, "size_bytes": 8192, "shape": [2048], "category": "ffn", "layer_id": 13, "component": "norm", "component_type": "FFN Norm"}, {"name": "blk.13.attn_k.weight", "offset_start": 772586400, "offset_end": 773634976, "size_bytes": 1048576, "shape": [2048, 256], "category": "attention", "layer_id": 13, "component": "key", "component_type": "Attention K"}, {"name": "blk.13.attn_output.weight", "offset_start": 773634976, "offset_end": 782023584, "size_bytes": 8388608, "shape": [2048, 2048], "category": "attention", "layer_id": 13, "component": "output", "component_type": "Output Projection"}, {"name": "blk.13.attn_q.weight", "offset_start": 782023584, "offset_end": 790412192, "size_bytes": 8388608, "shape": [2048, 2048], "category": "attention", "layer_id": 13, "component": "query", "component_type": "Attention Q"}, {"name": "blk.13.attn_v.weight", "offset_start": 790412192, "offset_end": 791460768, "size_bytes": 1048576, "shape": [2048, 256], "category": "attention", "layer_id": 13, "component": "value", "component_type": "Attention V"}, {"name": "blk.14.attn_norm.weight", "offset_start": 791460768, "offset_end": 791468960, "size_bytes": 8192, "shape": [2048], "category": "attention", "layer_id": 14, "component": "norm", "component_type": "Attention Norm"}, {"name": "blk.14.ffn_down.weight", "offset_start": 791468960, "offset_end": 814537632, "size_bytes": 23068672, "shape": [5632, 2048], "category": "ffn", "layer_id": 14, "component": "down", "component_type": "FFN Down"}, {"name": "blk.14.ffn_gate.weight", "offset_start": 814537632, "offset_end": 837606304, "size_bytes": 23068672, "shape": [2048, 5632], "category": "ffn", "layer_id": 14, "component": "gate", "component_type": "FFN Gate"}, {"name": "blk.14.ffn_up.weight", "offset_start": 837606304, "offset_end": 860674976, "size_bytes": 23068672, "shape": [2048, 5632], "category": "ffn", "layer_id": 14, "component": "up", "component_type": "FFN Up"}, {"name": "blk.14.ffn_norm.weight", "offset_start": 860674976, "offset_end": 860683168, "size_bytes": 8192, "shape": [2048], "category": "ffn", "layer_id": 14, "component": "norm", "component_type": "FFN Norm"}, {"name": "blk.14.attn_k.weight", "offset_start": 860683168, "offset_end": 861731744, "size_bytes": 1048576, "shape": [2048, 256], "category": "attention", "layer_id": 14, "component": "key", "component_type": "Attention K"}, {"name": "blk.14.attn_output.weight", "offset_start": 861731744, "offset_end": 870120352, "size_bytes": 8388608, "shape": [2048, 2048], "category": "attention", "layer_id": 14, "component": "output", "component_type": "Output Projection"}, {"name": "blk.14.attn_q.weight", "offset_start": 870120352, "offset_end": 878508960, "size_bytes": 8388608, "shape": [2048, 2048], "category": "attention", "layer_id": 14, "component": "query", "component_type": "Attention Q"}, {"name": "blk.14.attn_v.weight", "offset_start": 878508960, "offset_end": 879557536, "size_bytes": 1048576, "shape": [2048, 256], "category": "attention", "layer_id": 14, "component": "value", "component_type": "Attention V"}, {"name": "blk.15.attn_norm.weight", "offset_start": 879557536, "offset_end": 879565728, "size_bytes": 8192, "shape": [2048], "category": "attention", "layer_id": 15, "component": "norm", "component_type": "Attention Norm"}, {"name": "blk.15.ffn_down.weight", "offset_start": 879565728, "offset_end": 902634400, "size_bytes": 23068672, "shape": [5632, 2048], "category": "ffn", "layer_id": 15, "component": "down", "component_type": "FFN Down"}, {"name": "blk.15.ffn_gate.weight", "offset_start": 902634400, "offset_end": 925703072, "size_bytes": 23068672, "shape": [2048, 5632], "category": "ffn", "layer_id": 15, "component": "gate", "component_type": "FFN Gate"}, {"name": "blk.15.ffn_up.weight", "offset_start": 925703072, "offset_end": 948771744, "size_bytes": 23068672, "shape": [2048, 5632], "category": "ffn", "layer_id": 15, "component": "up", "component_type": "FFN Up"}, {"name": "blk.15.ffn_norm.weight", "offset_start": 948771744, "offset_end": 948779936, "size_bytes": 8192, "shape": [2048], "category": "ffn", "layer_id": 15, "component": "norm", "component_type": "FFN Norm"}, {"name": "blk.15.attn_k.weight", "offset_start": 948779936, "offset_end": 949828512, "size_bytes": 1048576, "shape": [2048, 256], "category": "attention", "layer_id": 15, "component": "key", "component_type": "Attention K"}, {"name": "blk.15.attn_output.weight", "offset_start": 949828512, "offset_end": 958217120, "size_bytes": 8388608, "shape": [2048, 2048], "category": "attention", "layer_id": 15, "component": "output", "component_type": "Output Projection"}, {"name": "blk.15.attn_q.weight", "offset_start": 958217120, "offset_end": 966605728, "size_bytes": 8388608, "shape": [2048, 2048], "category": "attention", "layer_id": 15, "component": "query", "component_type": "Attention Q"}, {"name": "blk.15.attn_v.weight", "offset_start": 966605728, "offset_end": 967654304, "size_bytes": 1048576, "shape": [2048, 256], "category": "attention", "layer_id": 15, "component": "value", "component_type": "Attention V"}, {"name": "blk.16.attn_norm.weight", "offset_start": 967654304, "offset_end": 967662496, "size_bytes": 8192, "shape": [2048], "category": "attention", "layer_id": 16, "component": "norm", "component_type": "Attention Norm"}, {"name": "blk.16.ffn_down.weight", "offset_start": 967662496, "offset_end": 990731168, "size_bytes": 23068672, "shape": [5632, 2048], "category": "ffn", "layer_id": 16, "component": "down", "component_type": "FFN Down"}, {"name": "blk.16.ffn_gate.weight", "offset_start": 990731168, "offset_end": 1013799840, "size_bytes": 23068672, "shape": [2048, 5632], "category": "ffn", "layer_id": 16, "component": "gate", "component_type": "FFN Gate"}, {"name": "blk.16.ffn_up.weight", "offset_start": 1013799840, "offset_end": 1036868512, "size_bytes": 23068672, "shape": [2048, 5632], "category": "ffn", "layer_id": 16, "component": "up", "component_type": "FFN Up"}, {"name": "blk.16.ffn_norm.weight", "offset_start": 1036868512, "offset_end": 1036876704, "size_bytes": 8192, "shape": [2048], "category": "ffn", "layer_id": 16, "component": "norm", "component_type": "FFN Norm"}, {"name": "blk.16.attn_k.weight", "offset_start": 1036876704, "offset_end": 1037925280, "size_bytes": 1048576, "shape": [2048, 256], "category": "attention", "layer_id": 16, "component": "key", "component_type": "Attention K"}, {"name": "blk.16.attn_output.weight", "offset_start": 1037925280, "offset_end": 1046313888, "size_bytes": 8388608, "shape": [2048, 2048], "category": "attention", "layer_id": 16, "component": "output", "component_type": "Output Projection"}, {"name": "blk.16.attn_q.weight", "offset_start": 1046313888, "offset_end": 1054702496, "size_bytes": 8388608, "shape": [2048, 2048], "category": "attention", "layer_id": 16, "component": "query", "component_type": "Attention Q"}, {"name": "blk.16.attn_v.weight", "offset_start": 1054702496, "offset_end": 1055751072, "size_bytes": 1048576, "shape": [2048, 256], "category": "attention", "layer_id": 16, "component": "value", "component_type": "Attention V"}, {"name": "blk.17.attn_norm.weight", "offset_start": 1055751072, "offset_end": 1055759264, "size_bytes": 8192, "shape": [2048], "category": "attention", "layer_id": 17, "component": "norm", "component_type": "Attention Norm"}, {"name": "blk.17.ffn_down.weight", "offset_start": 1055759264, "offset_end": 1078827936, "size_bytes": 23068672, "shape": [5632, 2048], "category": "ffn", "layer_id": 17, "component": "down", "component_type": "FFN Down"}, {"name": "blk.17.ffn_gate.weight", "offset_start": 1078827936, "offset_end": 1101896608, "size_bytes": 23068672, "shape": [2048, 5632], "category": "ffn", "layer_id": 17, "component": "gate", "component_type": "FFN Gate"}, {"name": "blk.17.ffn_up.weight", "offset_start": 1101896608, "offset_end": 1124965280, "size_bytes": 23068672, "shape": [2048, 5632], "category": "ffn", "layer_id": 17, "component": "up", "component_type": "FFN Up"}, {"name": "blk.17.ffn_norm.weight", "offset_start": 1124965280, "offset_end": 1124973472, "size_bytes": 8192, "shape": [2048], "category": "ffn", "layer_id": 17, "component": "norm", "component_type": "FFN Norm"}, {"name": "blk.17.attn_k.weight", "offset_start": 1124973472, "offset_end": 1126022048, "size_bytes": 1048576, "shape": [2048, 256], "category": "attention", "layer_id": 17, "component": "key", "component_type": "Attention K"}, {"name": "blk.17.attn_output.weight", "offset_start": 1126022048, "offset_end": 1134410656, "size_bytes": 8388608, "shape": [2048, 2048], "category": "attention", "layer_id": 17, "component": "output", "component_type": "Output Projection"}, {"name": "blk.17.attn_q.weight", "offset_start": 1134410656, "offset_end": 1142799264, "size_bytes": 8388608, "shape": [2048, 2048], "category": "attention", "layer_id": 17, "component": "query", "component_type": "Attention Q"}, {"name": "blk.17.attn_v.weight", "offset_start": 1142799264, "offset_end": 1143847840, "size_bytes": 1048576, "shape": [2048, 256], "category": "attention", "layer_id": 17, "component": "value", "component_type": "Attention V"}, {"name": "blk.18.attn_norm.weight", "offset_start": 1143847840, "offset_end": 1143856032, "size_bytes": 8192, "shape": [2048], "category": "attention", "layer_id": 18, "component": "norm", "component_type": "Attention Norm"}, {"name": "blk.18.ffn_down.weight", "offset_start": 1143856032, "offset_end": 1166924704, "size_bytes": 23068672, "shape": [5632, 2048], "category": "ffn", "layer_id": 18, "component": "down", "component_type": "FFN Down"}, {"name": "blk.18.ffn_gate.weight", "offset_start": 1166924704, "offset_end": 1189993376, "size_bytes": 23068672, "shape": [2048, 5632], "category": "ffn", "layer_id": 18, "component": "gate", "component_type": "FFN Gate"}, {"name": "blk.18.ffn_up.weight", "offset_start": 1189993376, "offset_end": 1213062048, "size_bytes": 23068672, "shape": [2048, 5632], "category": "ffn", "layer_id": 18, "component": "up", "component_type": "FFN Up"}, {"name": "blk.18.ffn_norm.weight", "offset_start": 1213062048, "offset_end": 1213070240, "size_bytes": 8192, "shape": [2048], "category": "ffn", "layer_id": 18, "component": "norm", "component_type": "FFN Norm"}, {"name": "blk.18.attn_k.weight", "offset_start": 1213070240, "offset_end": 1214118816, "size_bytes": 1048576, "shape": [2048, 256], "category": "attention", "layer_id": 18, "component": "key", "component_type": "Attention K"}, {"name": "blk.18.attn_output.weight", "offset_start": 1214118816, "offset_end": 1222507424, "size_bytes": 8388608, "shape": [2048, 2048], "category": "attention", "layer_id": 18, "component": "output", "component_type": "Output Projection"}, {"name": "blk.18.attn_q.weight", "offset_start": 1222507424, "offset_end": 1230896032, "size_bytes": 8388608, "shape": [2048, 2048], "category": "attention", "layer_id": 18, "component": "query", "component_type": "Attention Q"}, {"name": "blk.18.attn_v.weight", "offset_start": 1230896032, "offset_end": 1231944608, "size_bytes": 1048576, "shape": [2048, 256], "category": "attention", "layer_id": 18, "component": "value", "component_type": "Attention V"}, {"name": "blk.19.attn_norm.weight", "offset_start": 1231944608, "offset_end": 1231952800, "size_bytes": 8192, "shape": [2048], "category": "attention", "layer_id": 19, "component": "norm", "component_type": "Attention Norm"}, {"name": "blk.19.ffn_down.weight", "offset_start": 1231952800, "offset_end": 1255021472, "size_bytes": 23068672, "shape": [5632, 2048], "category": "ffn", "layer_id": 19, "component": "down", "component_type": "FFN Down"}, {"name": "blk.19.ffn_gate.weight", "offset_start": 1255021472, "offset_end": 1278090144, "size_bytes": 23068672, "shape": [2048, 5632], "category": "ffn", "layer_id": 19, "component": "gate", "component_type": "FFN Gate"}, {"name": "blk.19.ffn_up.weight", "offset_start": 1278090144, "offset_end": 1301158816, "size_bytes": 23068672, "shape": [2048, 5632], "category": "ffn", "layer_id": 19, "component": "up", "component_type": "FFN Up"}, {"name": "blk.19.ffn_norm.weight", "offset_start": 1301158816, "offset_end": 1301167008, "size_bytes": 8192, "shape": [2048], "category": "ffn", "layer_id": 19, "component": "norm", "component_type": "FFN Norm"}, {"name": "blk.19.attn_k.weight", "offset_start": 1301167008, "offset_end": 1302215584, "size_bytes": 1048576, "shape": [2048, 256], "category": "attention", "layer_id": 19, "component": "key", "component_type": "Attention K"}, {"name": "blk.19.attn_output.weight", "offset_start": 1302215584, "offset_end": 1310604192, "size_bytes": 8388608, "shape": [2048, 2048], "category": "attention", "layer_id": 19, "component": "output", "component_type": "Output Projection"}, {"name": "blk.19.attn_q.weight", "offset_start": 1310604192, "offset_end": 1318992800, "size_bytes": 8388608, "shape": [2048, 2048], "category": "attention", "layer_id": 19, "component": "query", "component_type": "Attention Q"}, {"name": "blk.19.attn_v.weight", "offset_start": 1318992800, "offset_end": 1320041376, "size_bytes": 1048576, "shape": [2048, 256], "category": "attention", "layer_id": 19, "component": "value", "component_type": "Attention V"}, {"name": "blk.2.attn_norm.weight", "offset_start": 1320041376, "offset_end": 1320049568, "size_bytes": 8192, "shape": [2048], "category": "attention", "layer_id": 2, "component": "norm", "component_type": "Attention Norm"}, {"name": "blk.2.ffn_down.weight", "offset_start": 1320049568, "offset_end": 1343118240, "size_bytes": 23068672, "shape": [5632, 2048], "category": "ffn", "layer_id": 2, "component": "down", "component_type": "FFN Down"}, {"name": "blk.2.ffn_gate.weight", "offset_start": 1343118240, "offset_end": 1366186912, "size_bytes": 23068672, "shape": [2048, 5632], "category": "ffn", "layer_id": 2, "component": "gate", "component_type": "FFN Gate"}, {"name": "blk.2.ffn_up.weight", "offset_start": 1366186912, "offset_end": 1389255584, "size_bytes": 23068672, "shape": [2048, 5632], "category": "ffn", "layer_id": 2, "component": "up", "component_type": "FFN Up"}, {"name": "blk.2.ffn_norm.weight", "offset_start": 1389255584, "offset_end": 1389263776, "size_bytes": 8192, "shape": [2048], "category": "ffn", "layer_id": 2, "component": "norm", "component_type": "FFN Norm"}, {"name": "blk.2.attn_k.weight", "offset_start": 1389263776, "offset_end": 1390312352, "size_bytes": 1048576, "shape": [2048, 256], "category": "attention", "layer_id": 2, "component": "key", "component_type": "Attention K"}, {"name": "blk.2.attn_output.weight", "offset_start": 1390312352, "offset_end": 1398700960, "size_bytes": 8388608, "shape": [2048, 2048], "category": "attention", "layer_id": 2, "component": "output", "component_type": "Output Projection"}, {"name": "blk.2.attn_q.weight", "offset_start": 1398700960, "offset_end": 1407089568, "size_bytes": 8388608, "shape": [2048, 2048], "category": "attention", "layer_id": 2, "component": "query", "component_type": "Attention Q"}, {"name": "blk.2.attn_v.weight", "offset_start": 1407089568, "offset_end": 1408138144, "size_bytes": 1048576, "shape": [2048, 256], "category": "attention", "layer_id": 2, "component": "value", "component_type": "Attention V"}, {"name": "blk.20.attn_norm.weight", "offset_start": 1408138144, "offset_end": 1408146336, "size_bytes": 8192, "shape": [2048], "category": "attention", "layer_id": 20, "component": "norm", "component_type": "Attention Norm"}, {"name": "blk.20.ffn_down.weight", "offset_start": 1408146336, "offset_end": 1431215008, "size_bytes": 23068672, "shape": [5632, 2048], "category": "ffn", "layer_id": 20, "component": "down", "component_type": "FFN Down"}, {"name": "blk.20.ffn_gate.weight", "offset_start": 1431215008, "offset_end": 1454283680, "size_bytes": 23068672, "shape": [2048, 5632], "category": "ffn", "layer_id": 20, "component": "gate", "component_type": "FFN Gate"}, {"name": "blk.20.ffn_up.weight", "offset_start": 1454283680, "offset_end": 1477352352, "size_bytes": 23068672, "shape": [2048, 5632], "category": "ffn", "layer_id": 20, "component": "up", "component_type": "FFN Up"}, {"name": "blk.20.ffn_norm.weight", "offset_start": 1477352352, "offset_end": 1477360544, "size_bytes": 8192, "shape": [2048], "category": "ffn", "layer_id": 20, "component": "norm", "component_type": "FFN Norm"}, {"name": "blk.20.attn_k.weight", "offset_start": 1477360544, "offset_end": 1478409120, "size_bytes": 1048576, "shape": [2048, 256], "category": "attention", "layer_id": 20, "component": "key", "component_type": "Attention K"}, {"name": "blk.20.attn_output.weight", "offset_start": 1478409120, "offset_end": 1486797728, "size_bytes": 8388608, "shape": [2048, 2048], "category": "attention", "layer_id": 20, "component": "output", "component_type": "Output Projection"}, {"name": "blk.20.attn_q.weight", "offset_start": 1486797728, "offset_end": 1495186336, "size_bytes": 8388608, "shape": [2048, 2048], "category": "attention", "layer_id": 20, "component": "query", "component_type": "Attention Q"}, {"name": "blk.20.attn_v.weight", "offset_start": 1495186336, "offset_end": 1496234912, "size_bytes": 1048576, "shape": [2048, 256], "category": "attention", "layer_id": 20, "component": "value", "component_type": "Attention V"}, {"name": "blk.21.attn_norm.weight", "offset_start": 1496234912, "offset_end": 1496243104, "size_bytes": 8192, "shape": [2048], "category": "attention", "layer_id": 21, "component": "norm", "component_type": "Attention Norm"}, {"name": "blk.21.ffn_down.weight", "offset_start": 1496243104, "offset_end": 1519311776, "size_bytes": 23068672, "shape": [5632, 2048], "category": "ffn", "layer_id": 21, "component": "down", "component_type": "FFN Down"}, {"name": "blk.21.ffn_gate.weight", "offset_start": 1519311776, "offset_end": 1542380448, "size_bytes": 23068672, "shape": [2048, 5632], "category": "ffn", "layer_id": 21, "component": "gate", "component_type": "FFN Gate"}, {"name": "blk.21.ffn_up.weight", "offset_start": 1542380448, "offset_end": 1565449120, "size_bytes": 23068672, "shape": [2048, 5632], "category": "ffn", "layer_id": 21, "component": "up", "component_type": "FFN Up"}, {"name": "blk.21.ffn_norm.weight", "offset_start": 1565449120, "offset_end": 1565457312, "size_bytes": 8192, "shape": [2048], "category": "ffn", "layer_id": 21, "component": "norm", "component_type": "FFN Norm"}, {"name": "blk.21.attn_k.weight", "offset_start": 1565457312, "offset_end": 1566505888, "size_bytes": 1048576, "shape": [2048, 256], "category": "attention", "layer_id": 21, "component": "key", "component_type": "Attention K"}, {"name": "blk.21.attn_output.weight", "offset_start": 1566505888, "offset_end": 1574894496, "size_bytes": 8388608, "shape": [2048, 2048], "category": "attention", "layer_id": 21, "component": "output", "component_type": "Output Projection"}, {"name": "blk.21.attn_q.weight", "offset_start": 1574894496, "offset_end": 1583283104, "size_bytes": 8388608, "shape": [2048, 2048], "category": "attention", "layer_id": 21, "component": "query", "component_type": "Attention Q"}, {"name": "blk.21.attn_v.weight", "offset_start": 1583283104, "offset_end": 1584331680, "size_bytes": 1048576, "shape": [2048, 256], "category": "attention", "layer_id": 21, "component": "value", "component_type": "Attention V"}, {"name": "blk.3.attn_norm.weight", "offset_start": 1584331680, "offset_end": 1584339872, "size_bytes": 8192, "shape": [2048], "category": "attention", "layer_id": 3, "component": "norm", "component_type": "Attention Norm"}, {"name": "blk.3.ffn_down.weight", "offset_start": 1584339872, "offset_end": 1607408544, "size_bytes": 23068672, "shape": [5632, 2048], "category": "ffn", "layer_id": 3, "component": "down", "component_type": "FFN Down"}, {"name": "blk.3.ffn_gate.weight", "offset_start": 1607408544, "offset_end": 1630477216, "size_bytes": 23068672, "shape": [2048, 5632], "category": "ffn", "layer_id": 3, "component": "gate", "component_type": "FFN Gate"}, {"name": "blk.3.ffn_up.weight", "offset_start": 1630477216, "offset_end": 1653545888, "size_bytes": 23068672, "shape": [2048, 5632], "category": "ffn", "layer_id": 3, "component": "up", "component_type": "FFN Up"}, {"name": "blk.3.ffn_norm.weight", "offset_start": 1653545888, "offset_end": 1653554080, "size_bytes": 8192, "shape": [2048], "category": "ffn", "layer_id": 3, "component": "norm", "component_type": "FFN Norm"}, {"name": "blk.3.attn_k.weight", "offset_start": 1653554080, "offset_end": 1654602656, "size_bytes": 1048576, "shape": [2048, 256], "category": "attention", "layer_id": 3, "component": "key", "component_type": "Attention K"}, {"name": "blk.3.attn_output.weight", "offset_start": 1654602656, "offset_end": 1662991264, "size_bytes": 8388608, "shape": [2048, 2048], "category": "attention", "layer_id": 3, "component": "output", "component_type": "Output Projection"}, {"name": "blk.3.attn_q.weight", "offset_start": 1662991264, "offset_end": 1671379872, "size_bytes": 8388608, "shape": [2048, 2048], "category": "attention", "layer_id": 3, "component": "query", "component_type": "Attention Q"}, {"name": "blk.3.attn_v.weight", "offset_start": 1671379872, "offset_end": 1672428448, "size_bytes": 1048576, "shape": [2048, 256], "category": "attention", "layer_id": 3, "component": "value", "component_type": "Attention V"}, {"name": "blk.4.attn_norm.weight", "offset_start": 1672428448, "offset_end": 1672436640, "size_bytes": 8192, "shape": [2048], "category": "attention", "layer_id": 4, "component": "norm", "component_type": "Attention Norm"}, {"name": "blk.4.ffn_down.weight", "offset_start": 1672436640, "offset_end": 1695505312, "size_bytes": 23068672, "shape": [5632, 2048], "category": "ffn", "layer_id": 4, "component": "down", "component_type": "FFN Down"}, {"name": "blk.4.ffn_gate.weight", "offset_start": 1695505312, "offset_end": 1718573984, "size_bytes": 23068672, "shape": [2048, 5632], "category": "ffn", "layer_id": 4, "component": "gate", "component_type": "FFN Gate"}, {"name": "blk.4.ffn_up.weight", "offset_start": 1718573984, "offset_end": 1741642656, "size_bytes": 23068672, "shape": [2048, 5632], "category": "ffn", "layer_id": 4, "component": "up", "component_type": "FFN Up"}, {"name": "blk.4.ffn_norm.weight", "offset_start": 1741642656, "offset_end": 1741650848, "size_bytes": 8192, "shape": [2048], "category": "ffn", "layer_id": 4, "component": "norm", "component_type": "FFN Norm"}, {"name": "blk.4.attn_k.weight", "offset_start": 1741650848, "offset_end": 1742699424, "size_bytes": 1048576, "shape": [2048, 256], "category": "attention", "layer_id": 4, "component": "key", "component_type": "Attention K"}, {"name": "blk.4.attn_output.weight", "offset_start": 1742699424, "offset_end": 1751088032, "size_bytes": 8388608, "shape": [2048, 2048], "category": "attention", "layer_id": 4, "component": "output", "component_type": "Output Projection"}, {"name": "blk.4.attn_q.weight", "offset_start": 1751088032, "offset_end": 1759476640, "size_bytes": 8388608, "shape": [2048, 2048], "category": "attention", "layer_id": 4, "component": "query", "component_type": "Attention Q"}, {"name": "blk.4.attn_v.weight", "offset_start": 1759476640, "offset_end": 1760525216, "size_bytes": 1048576, "shape": [2048, 256], "category": "attention", "layer_id": 4, "component": "value", "component_type": "Attention V"}, {"name": "blk.5.attn_norm.weight", "offset_start": 1760525216, "offset_end": 1760533408, "size_bytes": 8192, "shape": [2048], "category": "attention", "layer_id": 5, "component": "norm", "component_type": "Attention Norm"}, {"name": "blk.5.ffn_down.weight", "offset_start": 1760533408, "offset_end": 1783602080, "size_bytes": 23068672, "shape": [5632, 2048], "category": "ffn", "layer_id": 5, "component": "down", "component_type": "FFN Down"}, {"name": "blk.5.ffn_gate.weight", "offset_start": 1783602080, "offset_end": 1806670752, "size_bytes": 23068672, "shape": [2048, 5632], "category": "ffn", "layer_id": 5, "component": "gate", "component_type": "FFN Gate"}, {"name": "blk.5.ffn_up.weight", "offset_start": 1806670752, "offset_end": 1829739424, "size_bytes": 23068672, "shape": [2048, 5632], "category": "ffn", "layer_id": 5, "component": "up", "component_type": "FFN Up"}, {"name": "blk.5.ffn_norm.weight", "offset_start": 1829739424, "offset_end": 1829747616, "size_bytes": 8192, "shape": [2048], "category": "ffn", "layer_id": 5, "component": "norm", "component_type": "FFN Norm"}, {"name": "blk.5.attn_k.weight", "offset_start": 1829747616, "offset_end": 1830796192, "size_bytes": 1048576, "shape": [2048, 256], "category": "attention", "layer_id": 5, "component": "key", "component_type": "Attention K"}, {"name": "blk.5.attn_output.weight", "offset_start": 1830796192, "offset_end": 1839184800, "size_bytes": 8388608, "shape": [2048, 2048], "category": "attention", "layer_id": 5, "component": "output", "component_type": "Output Projection"}, {"name": "blk.5.attn_q.weight", "offset_start": 1839184800, "offset_end": 1847573408, "size_bytes": 8388608, "shape": [2048, 2048], "category": "attention", "layer_id": 5, "component": "query", "component_type": "Attention Q"}, {"name": "blk.5.attn_v.weight", "offset_start": 1847573408, "offset_end": 1848621984, "size_bytes": 1048576, "shape": [2048, 256], "category": "attention", "layer_id": 5, "component": "value", "component_type": "Attention V"}, {"name": "blk.6.attn_norm.weight", "offset_start": 1848621984, "offset_end": 1848630176, "size_bytes": 8192, "shape": [2048], "category": "attention", "layer_id": 6, "component": "norm", "component_type": "Attention Norm"}, {"name": "blk.6.ffn_down.weight", "offset_start": 1848630176, "offset_end": 1871698848, "size_bytes": 23068672, "shape": [5632, 2048], "category": "ffn", "layer_id": 6, "component": "down", "component_type": "FFN Down"}, {"name": "blk.6.ffn_gate.weight", "offset_start": 1871698848, "offset_end": 1894767520, "size_bytes": 23068672, "shape": [2048, 5632], "category": "ffn", "layer_id": 6, "component": "gate", "component_type": "FFN Gate"}, {"name": "blk.6.ffn_up.weight", "offset_start": 1894767520, "offset_end": 1917836192, "size_bytes": 23068672, "shape": [2048, 5632], "category": "ffn", "layer_id": 6, "component": "up", "component_type": "FFN Up"}, {"name": "blk.6.ffn_norm.weight", "offset_start": 1917836192, "offset_end": 1917844384, "size_bytes": 8192, "shape": [2048], "category": "ffn", "layer_id": 6, "component": "norm", "component_type": "FFN Norm"}, {"name": "blk.6.attn_k.weight", "offset_start": 1917844384, "offset_end": 1918892960, "size_bytes": 1048576, "shape": [2048, 256], "category": "attention", "layer_id": 6, "component": "key", "component_type": "Attention K"}, {"name": "blk.6.attn_output.weight", "offset_start": 1918892960, "offset_end": 1927281568, "size_bytes": 8388608, "shape": [2048, 2048], "category": "attention", "layer_id": 6, "component": "output", "component_type": "Output Projection"}, {"name": "blk.6.attn_q.weight", "offset_start": 1927281568, "offset_end": 1935670176, "size_bytes": 8388608, "shape": [2048, 2048], "category": "attention", "layer_id": 6, "component": "query", "component_type": "Attention Q"}, {"name": "blk.6.attn_v.weight", "offset_start": 1935670176, "offset_end": 1936718752, "size_bytes": 1048576, "shape": [2048, 256], "category": "attention", "layer_id": 6, "component": "value", "component_type": "Attention V"}, {"name": "blk.7.attn_norm.weight", "offset_start": 1936718752, "offset_end": 1936726944, "size_bytes": 8192, "shape": [2048], "category": "attention", "layer_id": 7, "component": "norm", "component_type": "Attention Norm"}, {"name": "blk.7.ffn_down.weight", "offset_start": 1936726944, "offset_end": 1959795616, "size_bytes": 23068672, "shape": [5632, 2048], "category": "ffn", "layer_id": 7, "component": "down", "component_type": "FFN Down"}, {"name": "blk.7.ffn_gate.weight", "offset_start": 1959795616, "offset_end": 1982864288, "size_bytes": 23068672, "shape": [2048, 5632], "category": "ffn", "layer_id": 7, "component": "gate", "component_type": "FFN Gate"}, {"name": "blk.7.ffn_up.weight", "offset_start": 1982864288, "offset_end": 2005932960, "size_bytes": 23068672, "shape": [2048, 5632], "category": "ffn", "layer_id": 7, "component": "up", "component_type": "FFN Up"}, {"name": "blk.7.ffn_norm.weight", "offset_start": 2005932960, "offset_end": 2005941152, "size_bytes": 8192, "shape": [2048], "category": "ffn", "layer_id": 7, "component": "norm", "component_type": "FFN Norm"}, {"name": "blk.7.attn_k.weight", "offset_start": 2005941152, "offset_end": 2006989728, "size_bytes": 1048576, "shape": [2048, 256], "category": "attention", "layer_id": 7, "component": "key", "component_type": "Attention K"}, {"name": "blk.7.attn_output.weight", "offset_start": 2006989728, "offset_end": 2015378336, "size_bytes": 8388608, "shape": [2048, 2048], "category": "attention", "layer_id": 7, "component": "output", "component_type": "Output Projection"}, {"name": "blk.7.attn_q.weight", "offset_start": 2015378336, "offset_end": 2023766944, "size_bytes": 8388608, "shape": [2048, 2048], "category": "attention", "layer_id": 7, "component": "query", "component_type": "Attention Q"}, {"name": "blk.7.attn_v.weight", "offset_start": 2023766944, "offset_end": 2024815520, "size_bytes": 1048576, "shape": [2048, 256], "category": "attention", "layer_id": 7, "component": "value", "component_type": "Attention V"}, {"name": "blk.8.attn_norm.weight", "offset_start": 2024815520, "offset_end": 2024823712, "size_bytes": 8192, "shape": [2048], "category": "attention", "layer_id": 8, "component": "norm", "component_type": "Attention Norm"}, {"name": "blk.8.ffn_down.weight", "offset_start": 2024823712, "offset_end": 2047892384, "size_bytes": 23068672, "shape": [5632, 2048], "category": "ffn", "layer_id": 8, "component": "down", "component_type": "FFN Down"}, {"name": "blk.8.ffn_gate.weight", "offset_start": 2047892384, "offset_end": 2070961056, "size_bytes": 23068672, "shape": [2048, 5632], "category": "ffn", "layer_id": 8, "component": "gate", "component_type": "FFN Gate"}, {"name": "blk.8.ffn_up.weight", "offset_start": 2070961056, "offset_end": 2094029728, "size_bytes": 23068672, "shape": [2048, 5632], "category": "ffn", "layer_id": 8, "component": "up", "component_type": "FFN Up"}, {"name": "blk.8.ffn_norm.weight", "offset_start": 2094029728, "offset_end": 2094037920, "size_bytes": 8192, "shape": [2048], "category": "ffn", "layer_id": 8, "component": "norm", "component_type": "FFN Norm"}, {"name": "blk.8.attn_k.weight", "offset_start": 2094037920, "offset_end": 2095086496, "size_bytes": 1048576, "shape": [2048, 256], "category": "attention", "layer_id": 8, "component": "key", "component_type": "Attention K"}, {"name": "blk.8.attn_output.weight", "offset_start": 2095086496, "offset_end": 2103475104, "size_bytes": 8388608, "shape": [2048, 2048], "category": "attention", "layer_id": 8, "component": "output", "component_type": "Output Projection"}, {"name": "blk.8.attn_q.weight", "offset_start": 2103475104, "offset_end": 2111863712, "size_bytes": 8388608, "shape": [2048, 2048], "category": "attention", "layer_id": 8, "component": "query", "component_type": "Attention Q"}, {"name": "blk.8.attn_v.weight", "offset_start": 2111863712, "offset_end": 2112912288, "size_bytes": 1048576, "shape": [2048, 256], "category": "attention", "layer_id": 8, "component": "value", "component_type": "Attention V"}, {"name": "blk.9.attn_norm.weight", "offset_start": 2112912288, "offset_end": 2112920480, "size_bytes": 8192, "shape": [2048], "category": "attention", "layer_id": 9, "component": "norm", "component_type": "Attention Norm"}, {"name": "blk.9.ffn_down.weight", "offset_start": 2112920480, "offset_end": 2135989152, "size_bytes": 23068672, "shape": [5632, 2048], "category": "ffn", "layer_id": 9, "component": "down", "component_type": "FFN Down"}, {"name": "blk.9.ffn_gate.weight", "offset_start": 2135989152, "offset_end": 2159057824, "size_bytes": 23068672, "shape": [2048, 5632], "category": "ffn", "layer_id": 9, "component": "gate", "component_type": "FFN Gate"}, {"name": "blk.9.ffn_up.weight", "offset_start": 2159057824, "offset_end": 2182126496, "size_bytes": 23068672, "shape": [2048, 5632], "category": "ffn", "layer_id": 9, "component": "up", "component_type": "FFN Up"}, {"name": "blk.9.ffn_norm.weight", "offset_start": 2182126496, "offset_end": 2182134688, "size_bytes": 8192, "shape": [2048], "category": "ffn", "layer_id": 9, "component": "norm", "component_type": "FFN Norm"}, {"name": "blk.9.attn_k.weight", "offset_start": 2182134688, "offset_end": 2183183264, "size_bytes": 1048576, "shape": [2048, 256], "category": "attention", "layer_id": 9, "component": "key", "component_type": "Attention K"}, {"name": "blk.9.attn_output.weight", "offset_start": 2183183264, "offset_end": 2191571872, "size_bytes": 8388608, "shape": [2048, 2048], "category": "attention", "layer_id": 9, "component": "output", "component_type": "Output Projection"}, {"name": "blk.9.attn_q.weight", "offset_start": 2191571872, "offset_end": 2199960480, "size_bytes": 8388608, "shape": [2048, 2048], "category": "attention", "layer_id": 9, "component": "query", "component_type": "Attention Q"}, {"name": "blk.9.attn_v.weight", "offset_start": 2199960480, "offset_end": 2201009056, "size_bytes": 1048576, "shape": [2048, 256], "category": "attention", "layer_id": 9, "component": "value", "component_type": "Attention V"}, {"name": "output_norm.weight", "offset_start": 2201009056, "offset_end": 2201017248, "size_bytes": 8192, "shape": [2048], "category": "output", "layer_id": null, "component": "output", "component_type": "Output Projection"}]}