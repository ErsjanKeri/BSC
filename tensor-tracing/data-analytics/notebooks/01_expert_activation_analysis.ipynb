{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expert Activation Pattern Analysis\n",
    "\n",
    "**Goal**: Analyze MoE expert activation patterns across 5 domains to identify:\n",
    "1. Domain-specific expert specialization\n",
    "2. Temporal correlation patterns\n",
    "3. Layer-wise behavior differences\n",
    "4. Expert usage distributions\n",
    "\n",
    "**Data**: 5 domains × 100 tokens × 72 MoE ops/token × 4 experts/op = 144,000 expert activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded libraries successfully!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n",
    "from scipy import stats\n",
    "from scipy.stats import entropy\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Data path - CORRECTED\n",
    "DATA_DIR = Path('../../expert-analysis-1')\n",
    "\n",
    "print(\"Loaded libraries successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Loading\n",
    "\n",
    "Load all expert activations from 5 domains into a structured DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading expert activations from all domains...\n",
      "  Loading domain-1-code...\n",
      "    ✓ 29,088 activations\n",
      "  Loading domain-2-math...\n",
      "    ✓ 29,088 activations\n",
      "  Loading domain-3-creative...\n",
      "    ✓ 29,088 activations\n",
      "  Loading domain-4-factual...\n",
      "    ✓ 29,088 activations\n",
      "  Loading domain-5-mixed...\n",
      "    ✓ 29,088 activations\n",
      "\n",
      "✓ Total activations loaded: 145,440\n",
      "\n",
      "DataFrame shape: (145440, 6)\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>token_id</th>\n",
       "      <th>layer_id</th>\n",
       "      <th>component</th>\n",
       "      <th>expert_id</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>domain-1-code</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ffn_gate</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>domain-1-code</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ffn_gate</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>domain-1-code</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ffn_gate</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>domain-1-code</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ffn_gate</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>domain-1-code</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ffn_up</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>domain-1-code</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ffn_up</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>domain-1-code</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ffn_up</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>domain-1-code</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ffn_up</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>domain-1-code</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ffn_down</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>domain-1-code</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ffn_down</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          domain  token_id  layer_id component  expert_id  position\n",
       "0  domain-1-code         0         0  ffn_gate          9         0\n",
       "1  domain-1-code         0         0  ffn_gate          5         1\n",
       "2  domain-1-code         0         0  ffn_gate         24         2\n",
       "3  domain-1-code         0         0  ffn_gate          3         3\n",
       "4  domain-1-code         0         0    ffn_up          9         0\n",
       "5  domain-1-code         0         0    ffn_up          5         1\n",
       "6  domain-1-code         0         0    ffn_up         24         2\n",
       "7  domain-1-code         0         0    ffn_up          3         3\n",
       "8  domain-1-code         0         0  ffn_down          9         0\n",
       "9  domain-1-code         0         0  ffn_down          5         1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_expert_activations(domain_path):\n",
    "    \"\"\"\n",
    "    Extract all expert activations from a domain.\n",
    "    \n",
    "    Returns: List of dicts with columns:\n",
    "        - domain: str\n",
    "        - token_id: int\n",
    "        - layer_id: int\n",
    "        - component: str (ffn_down, ffn_gate, ffn_up)\n",
    "        - expert_id: int (0-31)\n",
    "        - position: int (0-3, which of top-4)\n",
    "    \"\"\"\n",
    "    domain_name = domain_path.name\n",
    "    activations = []\n",
    "    \n",
    "    # Load all 100 token traces\n",
    "    for token_id in range(100):\n",
    "        token_file = domain_path / 'traces' / f'token-{token_id:05d}.json'\n",
    "        \n",
    "        if not token_file.exists():\n",
    "            continue\n",
    "            \n",
    "        with open(token_file) as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Extract MUL_MAT_ID operations (MoE routing)\n",
    "        for entry in data['entries']:\n",
    "            if entry['operation_type'] != 'MUL_MAT_ID' or not entry['expert_ids']:\n",
    "                continue\n",
    "            \n",
    "            layer_id = entry['layer_id']\n",
    "            \n",
    "            # Identify component from destination name - FIXED\n",
    "            dst_name = entry['dst_name']\n",
    "            if 'ffn_moe_down' in dst_name:\n",
    "                component = 'ffn_down'\n",
    "            elif 'ffn_moe_gate' in dst_name:\n",
    "                component = 'ffn_gate'\n",
    "            elif 'ffn_moe_up' in dst_name:\n",
    "                component = 'ffn_up'\n",
    "            else:\n",
    "                component = 'unknown'\n",
    "            \n",
    "            # Record each selected expert (top-4)\n",
    "            for position, expert_id in enumerate(entry['expert_ids'][:4]):\n",
    "                activations.append({\n",
    "                    'domain': domain_name,\n",
    "                    'token_id': token_id,\n",
    "                    'layer_id': layer_id,\n",
    "                    'component': component,\n",
    "                    'expert_id': expert_id,\n",
    "                    'position': position  # 0=top choice, 3=4th choice\n",
    "                })\n",
    "    \n",
    "    return activations\n",
    "\n",
    "# Load all domains\n",
    "print(\"Loading expert activations from all domains...\")\n",
    "all_activations = []\n",
    "\n",
    "domains = ['domain-1-code', 'domain-2-math', 'domain-3-creative', \n",
    "           'domain-4-factual', 'domain-5-mixed']\n",
    "\n",
    "for domain_name in domains:\n",
    "    domain_path = DATA_DIR / domain_name\n",
    "    print(f\"  Loading {domain_name}...\")\n",
    "    activations = extract_expert_activations(domain_path)\n",
    "    all_activations.extend(activations)\n",
    "    print(f\"    ✓ {len(activations):,} activations\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(all_activations)\n",
    "\n",
    "print(f\"\\n✓ Total activations loaded: {len(df):,}\")\n",
    "print(f\"\\nDataFrame shape: {df.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Basic Statistics\n",
    "\n",
    "Understand the dataset structure and distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATASET OVERVIEW\n",
      "============================================================\n",
      "\n",
      "Total expert activations: 145,440\n",
      "Domains: 5\n",
      "Layers: 24 (IDs: 0-23)\n",
      "Components: <StringArray>\n",
      "['ffn_gate', 'ffn_up', 'ffn_down']\n",
      "Length: 3, dtype: str\n",
      "Expert IDs: 32 (range: 0-31)\n",
      "Tokens per domain: 100\n",
      "\n",
      "Activations per domain:\n",
      "domain\n",
      "domain-1-code        29088\n",
      "domain-2-math        29088\n",
      "domain-3-creative    29088\n",
      "domain-4-factual     29088\n",
      "domain-5-mixed       29088\n",
      "dtype: int64\n",
      "\n",
      "Activations per layer:\n",
      "  Min: 6060 (Layer 0)\n",
      "  Max: 6060 (Layer 0)\n",
      "  Mean: 6060\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"DATASET OVERVIEW\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nTotal expert activations: {len(df):,}\")\n",
    "print(f\"Domains: {df['domain'].nunique()}\")\n",
    "print(f\"Layers: {df['layer_id'].nunique()} (IDs: {df['layer_id'].min()}-{df['layer_id'].max()})\")\n",
    "print(f\"Components: {df['component'].unique()}\")\n",
    "print(f\"Expert IDs: {df['expert_id'].nunique()} (range: {df['expert_id'].min()}-{df['expert_id'].max()})\")\n",
    "print(f\"Tokens per domain: {df.groupby('domain')['token_id'].nunique().iloc[0]}\")\n",
    "\n",
    "# Activations per domain\n",
    "print(\"\\nActivations per domain:\")\n",
    "print(df.groupby('domain').size())\n",
    "\n",
    "# Activations per layer\n",
    "print(\"\\nActivations per layer:\")\n",
    "layer_counts = df.groupby('layer_id').size()\n",
    "print(f\"  Min: {layer_counts.min()} (Layer {layer_counts.idxmin()})\")\n",
    "print(f\"  Max: {layer_counts.max()} (Layer {layer_counts.idxmax()})\")\n",
    "print(f\"  Mean: {layer_counts.mean():.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Domain Comparison - First Look\n",
    "\n",
    "**Question**: Which experts are hot in each domain?\n",
    "\n",
    "Start with **ONE layer, ONE component** to see if domain clustering exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focus on Layer 0, ffn_down component\n",
    "layer_to_analyze = 0\n",
    "component_to_analyze = 'ffn_down'\n",
    "\n",
    "# Filter data\n",
    "subset = df[(df['layer_id'] == layer_to_analyze) & \n",
    "            (df['component'] == component_to_analyze)]\n",
    "\n",
    "print(f\"Layer {layer_to_analyze}, Component: {component_to_analyze}\")\n",
    "print(f\"Total activations: {len(subset):,}\")\n",
    "print(f\"Activations per domain: {len(subset) / 5:.0f}\")\n",
    "\n",
    "# Build Domain × Expert frequency matrix\n",
    "freq_matrix = subset.pivot_table(\n",
    "    index='domain',\n",
    "    columns='expert_id',\n",
    "    aggfunc='size',\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "# Convert to percentages (normalize by domain)\n",
    "freq_matrix_pct = freq_matrix.div(freq_matrix.sum(axis=1), axis=0) * 100\n",
    "\n",
    "print(\"\\nFrequency matrix (percentages):\")\n",
    "print(freq_matrix_pct)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(16, 6))\n",
    "sns.heatmap(freq_matrix_pct, annot=False, cmap='YlOrRd', \n",
    "            cbar_kws={'label': 'Usage %'},\n",
    "            xticklabels=True, yticklabels=True)\n",
    "plt.title(f'Expert Usage by Domain (Layer {layer_to_analyze}, {component_to_analyze})')\n",
    "plt.xlabel('Expert ID (0-31)')\n",
    "plt.ylabel('Domain')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nMost used experts per domain:\")\n",
    "for domain in domains:\n",
    "    top_experts = freq_matrix_pct.loc[domain].nlargest(5)\n",
    "    expert_ids = top_experts.index.tolist()\n",
    "    print(f\"  {domain}: Experts {expert_ids} ({top_experts.values.sum():.1f}% of usage)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Statistical Test for Domain Clustering\n",
    "\n",
    "**Question**: Are the observed domain differences statistically significant?\n",
    "\n",
    "Use Chi-square test for independence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Chi-square test on frequency matrix\n",
    "chi2, p_value, dof, expected = chi2_contingency(freq_matrix)\n",
    "\n",
    "print(\"Chi-Square Test for Independence\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Null hypothesis: Expert selection is independent of domain\")\n",
    "print(f\"\\nChi-square statistic: {chi2:.2f}\")\n",
    "print(f\"p-value: {p_value:.2e}\")\n",
    "print(f\"Degrees of freedom: {dof}\")\n",
    "\n",
    "if p_value < 0.001:\n",
    "    print(\"\\n✅ RESULT: HIGHLY SIGNIFICANT (p < 0.001)\")\n",
    "    print(\"   → Reject null hypothesis\")\n",
    "    print(\"   → Domains DO show different expert preferences!\")\n",
    "elif p_value < 0.05:\n",
    "    print(\"\\n✅ RESULT: SIGNIFICANT (p < 0.05)\")\n",
    "    print(\"   → Domains show different patterns\")\n",
    "else:\n",
    "    print(\"\\n❌ RESULT: NOT SIGNIFICANT\")\n",
    "    print(\"   → Expert selection appears independent of domain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Identify Domain-Specific vs General Experts\n",
    "\n",
    "Classify each expert as:\n",
    "- **Specialist**: Used heavily in one domain, rarely in others\n",
    "- **Generalist**: Used similarly across all domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate coefficient of variation for each expert across domains\n",
    "expert_variance = freq_matrix.std(axis=0) / (freq_matrix.mean(axis=0) + 1e-10)\n",
    "\n",
    "# High variance = specialist (used a lot in one domain, little in others)\n",
    "# Low variance = generalist (used similarly across domains)\n",
    "\n",
    "specialist_threshold = expert_variance.quantile(0.75)\n",
    "\n",
    "specialists = expert_variance[expert_variance > specialist_threshold].index.tolist()\n",
    "generalists = expert_variance[expert_variance < expert_variance.quantile(0.25)].index.tolist()\n",
    "\n",
    "print(\"Expert Classification\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nSpecialists (high variance): {len(specialists)} experts\")\n",
    "print(f\"  IDs: {specialists}\")\n",
    "\n",
    "print(f\"\\nGeneralists (low variance): {len(generalists)} experts\")\n",
    "print(f\"  IDs: {generalists}\")\n",
    "\n",
    "# For each specialist, identify its preferred domain\n",
    "print(\"\\nSpecialist Expert → Preferred Domain:\")\n",
    "for expert_id in specialists:\n",
    "    preferred_domain = freq_matrix[expert_id].idxmax()\n",
    "    usage_pct = freq_matrix_pct.loc[preferred_domain, expert_id]\n",
    "    print(f\"  Expert {expert_id}: {preferred_domain} ({usage_pct:.1f}% of its usage)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: All Layers Comparison\n",
    "\n",
    "Repeat the analysis for all 24 layers to see if patterns differ by depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each layer, calculate domain separation metric\n",
    "layer_separation = []\n",
    "\n",
    "for layer_id in range(24):\n",
    "    layer_data = df[(df['layer_id'] == layer_id) & \n",
    "                    (df['component'] == 'ffn_down')]\n",
    "    \n",
    "    if len(layer_data) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Build frequency matrix for this layer\n",
    "    layer_freq = layer_data.pivot_table(\n",
    "        index='domain',\n",
    "        columns='expert_id',\n",
    "        aggfunc='size',\n",
    "        fill_value=0\n",
    "    )\n",
    "    \n",
    "    # Chi-square test\n",
    "    chi2, p_value, _, _ = chi2_contingency(layer_freq)\n",
    "    \n",
    "    # Variance metric (how different are domains?)\n",
    "    # Normalize by domain first\n",
    "    layer_freq_norm = layer_freq.div(layer_freq.sum(axis=1), axis=0)\n",
    "    \n",
    "    # Calculate variance across domains for each expert, then average\n",
    "    avg_variance = layer_freq_norm.var(axis=0).mean()\n",
    "    \n",
    "    layer_separation.append({\n",
    "        'layer_id': layer_id,\n",
    "        'chi2': chi2,\n",
    "        'p_value': p_value,\n",
    "        'avg_variance': avg_variance,\n",
    "        'significant': p_value < 0.001\n",
    "    })\n",
    "\n",
    "sep_df = pd.DataFrame(layer_separation)\n",
    "\n",
    "print(\"Domain Separation by Layer\")\n",
    "print(\"=\" * 60)\n",
    "print(sep_df.to_string())\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "# Plot 1: Chi-square statistic\n",
    "axes[0].bar(sep_df['layer_id'], sep_df['chi2'])\n",
    "axes[0].set_xlabel('Layer ID')\n",
    "axes[0].set_ylabel('Chi-Square Statistic')\n",
    "axes[0].set_title('Domain Clustering Strength by Layer (Higher = More Domain-Specific)')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: P-value (log scale)\n",
    "axes[1].bar(sep_df['layer_id'], -np.log10(sep_df['p_value'] + 1e-300))\n",
    "axes[1].axhline(y=-np.log10(0.001), color='r', linestyle='--', label='p=0.001 threshold')\n",
    "axes[1].set_xlabel('Layer ID')\n",
    "axes[1].set_ylabel('-log10(p-value)')\n",
    "axes[1].set_title('Statistical Significance by Layer (Higher = More Significant)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Identify most interesting layers\n",
    "top_layers = sep_df.nlargest(5, 'chi2')['layer_id'].tolist()\n",
    "print(f\"\\nMost domain-specific layers: {top_layers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Deep Dive - Most Interesting Layer\n",
    "\n",
    "Pick the layer with strongest domain clustering and visualize all 3 components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting_layer = top_layers[0]\n",
    "\n",
    "print(f\"Analyzing Layer {interesting_layer} in detail...\")\n",
    "\n",
    "# Create 3 heatmaps (one per component)\n",
    "fig, axes = plt.subplots(3, 1, figsize=(16, 12))\n",
    "components = ['ffn_down', 'ffn_gate', 'ffn_up']\n",
    "\n",
    "for idx, component in enumerate(components):\n",
    "    # Filter data\n",
    "    comp_data = df[(df['layer_id'] == interesting_layer) & \n",
    "                   (df['component'] == component)]\n",
    "    \n",
    "    # Build matrix\n",
    "    matrix = comp_data.pivot_table(\n",
    "        index='domain',\n",
    "        columns='expert_id',\n",
    "        aggfunc='size',\n",
    "        fill_value=0\n",
    "    )\n",
    "    \n",
    "    # Normalize to percentages\n",
    "    matrix_pct = matrix.div(matrix.sum(axis=1), axis=0) * 100\n",
    "    \n",
    "    # Plot\n",
    "    sns.heatmap(matrix_pct, ax=axes[idx], cmap='YlOrRd', \n",
    "                annot=False, cbar_kws={'label': 'Usage %'},\n",
    "                vmin=0, vmax=matrix_pct.max().max())\n",
    "    axes[idx].set_title(f'Layer {interesting_layer} - {component} Expert Usage')\n",
    "    axes[idx].set_xlabel('Expert ID')\n",
    "    axes[idx].set_ylabel('Domain')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/figures/layer_{}_all_components.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n✓ Saved figure to outputs/figures/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Expert Diversity by Domain\n",
    "\n",
    "**Question**: Do some domains use experts more uniformly (high diversity) vs focused on few experts (low diversity)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Shannon entropy for each domain (measures diversity)\n",
    "# For Layer 0, ffn_down\n",
    "\n",
    "subset = df[(df['layer_id'] == 0) & (df['component'] == 'ffn_down')]\n",
    "\n",
    "domain_entropies = {}\n",
    "\n",
    "for domain in domains:\n",
    "    domain_data = subset[subset['domain'] == domain]\n",
    "    expert_counts = domain_data['expert_id'].value_counts(normalize=True)\n",
    "    \n",
    "    # Shannon entropy\n",
    "    H = entropy(expert_counts.values, base=2)\n",
    "    domain_entropies[domain] = H\n",
    "    \n",
    "    print(f\"{domain}: Entropy = {H:.2f} bits\")\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"  High entropy = Diverse (uses many experts equally)\")\n",
    "print(\"  Low entropy = Focused (dominated by few experts)\")\n",
    "print(f\"\\n  Max possible entropy: {np.log2(32):.2f} bits (uniform distribution)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9: Temporal Autocorrelation\n",
    "\n",
    "**Question**: Are expert selections correlated across tokens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For one domain, one layer, one component:\n",
    "# Build sequence of top expert across tokens 0-99\n",
    "\n",
    "domain_to_analyze = 'domain-1-code'\n",
    "layer_to_analyze = 0\n",
    "component_to_analyze = 'ffn_down'\n",
    "\n",
    "# Filter\n",
    "seq_data = df[(df['domain'] == domain_to_analyze) & \n",
    "              (df['layer_id'] == layer_to_analyze) & \n",
    "              (df['component'] == component_to_analyze) &\n",
    "              (df['position'] == 0)]  # Only top-1 expert\n",
    "\n",
    "# Sort by token\n",
    "seq_data = seq_data.sort_values('token_id')\n",
    "\n",
    "# Extract expert sequence\n",
    "expert_sequence = seq_data['expert_id'].values\n",
    "\n",
    "print(f\"Expert sequence length: {len(expert_sequence)}\")\n",
    "print(f\"First 20 tokens: {expert_sequence[:20]}\")\n",
    "\n",
    "# Compute autocorrelation\n",
    "from scipy.signal import correlate\n",
    "\n",
    "# Lag-1 autocorrelation (simple version)\n",
    "lag1_same = sum(expert_sequence[i] == expert_sequence[i+1] for i in range(len(expert_sequence)-1))\n",
    "lag1_prob = lag1_same / (len(expert_sequence) - 1)\n",
    "\n",
    "print(f\"\\nLag-1 autocorrelation:\")\n",
    "print(f\"  Same expert at t and t+1: {lag1_same}/{len(expert_sequence)-1} times\")\n",
    "print(f\"  Probability: {lag1_prob:.2%}\")\n",
    "print(f\"  Random baseline: {1/32:.2%} (1/32 if random)\")\n",
    "\n",
    "if lag1_prob > 0.2:\n",
    "    print(f\"\\n✅ Strong temporal correlation (>{0.2:.0%})\")\n",
    "    print(\"   → Experts are STICKY\")\n",
    "else:\n",
    "    print(f\"\\n❌ Weak correlation\")\n",
    "    print(\"   → Experts switch frequently\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 10: Next Steps\n",
    "\n",
    "Based on initial findings, determine which analyses to pursue:\n",
    "\n",
    "1. If domain clustering is strong → Focus on identifying domain-specific experts\n",
    "2. If temporal correlation is strong → Build transition matrices\n",
    "3. If layer differences are significant → Analyze early vs late layer behavior"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
